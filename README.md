# ü§ñ –ò–ò-—á–∞—Ç —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é

[![–õ–∏—Ü–µ–Ω–∑–∏—è: MIT](https://img.shields.io/badge/–õ–∏—Ü–µ–Ω–∑–∏—è-MIT-blue.svg)](LICENSE)
![Python 3.8+](https://img.shields.io/badge/Python-3.8+-3776AB?logo=python)
![HuggingFace](https://img.shields.io/badge/HuggingFace-Transformers-yellow?logo=huggingface)

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ GitHub
<div align="center">

![–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞](https://github-readme-stats.vercel.app/api?username=INVINCIBLEYTTW&show_icons=true&theme=dark&locale=ru)
![–Ø–∑—ã–∫–∏](https://github-readme-stats.vercel.app/api/top-langs/?username=INVINCIBLEYTTW&layout=compact&theme=dark&locale=ru)
![–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π](https://github-readme-stats.vercel.app/api/pin/?username=INVINCIBLEYTTW&repo=ai-chat&theme=dark)

</div>

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç
```bash
git clone https://github.com/INVINCIBLEYTTW/ai-chat.git
pip install -r requirements.txt
python chat.py --model=gpt2
üõ† –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
–ú–æ–¥–µ–ª–∏: GPT-2, Mistral-7B, LLaMA-3 (—á–µ—Ä–µ–∑ HuggingFace)

–ó–∞–ø—É—Å–∫: PyTorch 2.0+ (CPU/CUDA)

–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å: Gradio 3.45+

üìä –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π
–ú–æ–¥–µ–ª—å	–†–∞–∑–º–µ—Ä	–°–∫–æ—Ä–æ—Å—Ç—å (—Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫)	–ü–∞–º—è—Ç—å
GPT-2	500MB	45 (CPU)	2GB RAM
Mistral-7B	14GB	28 (CUDA)	8GB VRAM
üìå –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
python
from transformers import AutoModelForCausalLM
model = AutoModelForCausalLM.from_pretrained("gpt2")
<div align="center">
–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã

</div> 
